{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "from problem import get_test_data\n",
    "\n",
    "X_df, y_array = get_train_data()\n",
    "X_test_df, y_test_array = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (4,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "award = pd.read_csv('data/award_notices_RAMP.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # obtain features from award\n",
    "# award['Name_processed'] = award['incumbent_name'].str.lower()\n",
    "# award['Name_processed'] = award['Name_processed'].str.replace('[^\\w]','')\n",
    "# award['End_of_call_date'] = pd.to_datetime(award['End_of_call_date'], format='%Y-%m-%d', errors='coerce')\n",
    "# award['End_of_call_year'] = award['End_of_call_date'].dt.year\n",
    "# award_features = award.groupby(['Name_processed','End_of_call_year'])['amount'].agg(['count','sum'])\n",
    "\n",
    "# def zipcodes(X):\n",
    "#     zipcode_nums = pd.to_numeric(X['Zipcode'], errors='coerce')\n",
    "#     return zipcode_nums.values[:, np.newaxis]\n",
    "# zipcode_transformer = FunctionTransformer(zipcodes, validate=False)\n",
    "\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('impute', SimpleImputer(strategy='median'))])\n",
    "\n",
    "# def process_date(X):\n",
    "#     date = pd.to_datetime(X['Fiscal_year_end_date'], format='%Y-%m-%d')\n",
    "#     return np.c_[date.dt.year, date.dt.month, date.dt.day]\n",
    "# date_transformer = FunctionTransformer(process_date, validate=False)\n",
    "\n",
    "# def process_APE(X):\n",
    "#     APE = X['Activity_code (APE)'].str[:2]\n",
    "#     return pd.to_numeric(APE).values[:, np.newaxis]\n",
    "# APE_transformer = FunctionTransformer(process_APE, validate=False)\n",
    "\n",
    "# def merge_naive(X):\n",
    "#     X['Name'] = X['Name'].str.lower()     \n",
    "#     X['Name'] = X['Name'].str.replace('[^\\w]','')\n",
    "#     df = pd.merge(X, award_features, left_on=['Name','Year'], \n",
    "#                   right_on=['Name_processed','End_of_call_year'], how='left')\n",
    "#     return df[['count','sum']]\n",
    "# merge_transformer = FunctionTransformer(merge_naive, validate=False)\n",
    "\n",
    "# num_cols = ['Legal_ID', 'Headcount', \n",
    "#             'Fiscal_year_duration_in_months', 'Year']\n",
    "# zipcode_col = ['Zipcode']\n",
    "# date_cols = ['Fiscal_year_end_date']\n",
    "# APE_col = ['Activity_code (APE)']\n",
    "# merge_col = ['Name','Year']\n",
    "# drop_cols = ['Address', 'City']\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('zipcode', make_pipeline(zipcode_transformer, SimpleImputer(strategy='median')), zipcode_col),\n",
    "#         ('num', numeric_transformer, num_cols),\n",
    "#         ('date', make_pipeline(date_transformer, SimpleImputer(strategy='median')), date_cols),\n",
    "#         ('APE', make_pipeline(APE_transformer, SimpleImputer(strategy='median')), APE_col),\n",
    "#         ('merge', make_pipeline(merge_transformer, SimpleImputer(strategy='median')), merge_col),\n",
    "#         ('drop cols', 'drop', drop_cols),\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    true = np.maximum(5., np.log10(np.maximum(1., y_true)))\n",
    "    pred = np.maximum(5., np.log10(np.maximum(1., y_pred)))\n",
    "    \n",
    "    loss = np.mean(np.abs(true - pred))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "fan_loss = make_scorer(loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_toy = X_df[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z    804086\n",
       "A    339634\n",
       "B    216133\n",
       "C     96920\n",
       "D     16787\n",
       "F      2395\n",
       "E       887\n",
       "J       279\n",
       "G       133\n",
       "L        47\n",
       "S        30\n",
       "V        29\n",
       "K        29\n",
       "N        25\n",
       "W        21\n",
       "H        17\n",
       "1        16\n",
       "T        14\n",
       "3        13\n",
       "P        13\n",
       "M         9\n",
       "U         8\n",
       "6         6\n",
       "R         6\n",
       "5         6\n",
       "X         4\n",
       "0         4\n",
       "9         4\n",
       "2         3\n",
       "Name: Activity_code (APE), dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df['Activity_code (APE)'].str[-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_APE_char(X):\n",
    "    char_map = {'Z':9,\n",
    "                'A':8,\n",
    "                'B':7,\n",
    "                'C':6,\n",
    "                'D':5,\n",
    "                'F':4,\n",
    "                'E':3,\n",
    "                'J':2,\n",
    "                'G':1}\n",
    "    APEc = X['Activity_code (APE)'].str[-1]\n",
    "    return np.c_[[char_map[c] if c in char_map else 0 for c in APEc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [0],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [6],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [6],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [0],\n",
       "       [0],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_APE_char(X_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999    9329Z\n",
       "Name: Activity_code (APE), dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy['Activity_code (APE)'][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.OneHotEncoder(cols=['Year'])\n",
    "encoder.fit_transform(X_toy['Year']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "award['Name_processed'] = award['incumbent_name'].str.lower()\n",
    "award['Name_processed'] = award['Name_processed'].str.replace('[^\\w]','')\n",
    "award['End_of_call_date'] = pd.to_datetime(award['End_of_call_date'], format='%Y-%m-%d', errors='coerce')\n",
    "award['End_of_call_year'] = award['End_of_call_date'].dt.year\n",
    "award_features = award.groupby(['Name_processed','End_of_call_year'])['amount'].agg(['count','sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_APE(X):\n",
    "    APE1 = X['Activity_code (APE)'].str[:2]\n",
    "    APE2 = X['Activity_code (APE)'].str[:4]\n",
    "    char_map = {'Z':9.,\n",
    "                'A':8.,\n",
    "                'B':7.,\n",
    "                'C':6.,\n",
    "                'D':5.,\n",
    "                'F':4.,\n",
    "                'E':3.,\n",
    "                'J':2.,\n",
    "                'G':1.}\n",
    "    APEc = X['Activity_code (APE)'].str[-1]\n",
    "    APEc = [char_map[c] if c in char_map else 0. for c in APEc]\n",
    "    return np.c_[pd.to_numeric(APE1, errors='coerce').values,\n",
    "                 pd.to_numeric(APE2, errors='coerce').values,\n",
    "                 APEc\n",
    "                 ]\n",
    "APE_transformer = FunctionTransformer(process_APE, validate=False)\n",
    "\n",
    "def merge_naive(X):\n",
    "    X['Name'] = X['Name'].str.lower()     \n",
    "    X['Name'] = X['Name'].str.replace('[^\\w]','')\n",
    "    df = pd.merge(X, award_features, left_on=['Name','Year'], \n",
    "                  right_on=['Name_processed','End_of_call_year'], how='left')\n",
    "    return df[['count','sum']]\n",
    "merge_award_transformer = FunctionTransformer(merge_naive, validate=False)\n",
    "\n",
    "def merge_headcounts(X):  \n",
    "    X['Name'] = X['Name'].str.lower()     \n",
    "    X['Name'] = X['Name'].str.replace('[^\\w]','')\n",
    "    \n",
    "    head_att = ['mean','max','min' ]\n",
    "    headcount_features = X.groupby(['Name'])['Headcount'].agg(head_att)    \n",
    "    df = pd.merge(X, headcount_features, left_on=['Name'], \n",
    "                right_on=['Name'], how='left')\n",
    "    return df[head_att]\n",
    "merge_head_transformer = FunctionTransformer(merge_headcounts, validate=False)\n",
    "\n",
    "def encode_year(X):\n",
    "    return np.c_[(X['Year']==2013.) * 1.,\n",
    "                 (X['Year']==2014.) * 1.,\n",
    "                 (X['Year']==2015.) * 1.,\n",
    "                 (X['Year']==2016.) * 1.,\n",
    "                 (X['Year']==2017.) * 1.,\n",
    "                 (X['Year']==2018.) * 1.]\n",
    "encode_year_transformer = FunctionTransformer(encode_year, validate=False)\n",
    "\n",
    "num_cols = ['Legal_ID', 'Headcount', 'Year']\n",
    "APE_col = ['Activity_code (APE)']\n",
    "merge_award_cols = ['Name','Year']\n",
    "merge_headcount_col = ['Name','Headcount']\n",
    "id_col = ['Legal_ID']\n",
    "head_col = ['Headcount']\n",
    "year_col = ['Year']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "            ('impute', SimpleImputer(strategy='median')),\n",
    "            #('scale', StandardScaler())\n",
    "            ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('num', numeric_transformer, num_cols),\n",
    "        ('ID', make_pipeline(SimpleImputer(strategy='mean')), id_col),\n",
    "        ('Headcount', make_pipeline(SimpleImputer(strategy='median')), head_col),\n",
    "        ('Year', make_pipeline(SimpleImputer(strategy='median')), year_col),\n",
    "        #('Year encoders', make_pipeline(encode_year_transformer, SimpleImputer(strategy='median')), year_col),\n",
    "        ('APE', make_pipeline(APE_transformer, SimpleImputer(strategy='median')), APE_col),\n",
    "        ('merge headcounts', make_pipeline(merge_head_transformer, SimpleImputer(strategy='median')), merge_headcount_col),\n",
    "        ('merge awards', make_pipeline(merge_award_transformer, SimpleImputer(strategy='median')), merge_award_cols),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:\n",
      "(1495948, 11)\n",
      "Test data shape:\n",
      "(520966, 11)\n"
     ]
    }
   ],
   "source": [
    "X_num_train = preprocessor.fit_transform(X_df)\n",
    "X_num_test = preprocessor.fit_transform(X_test_df)\n",
    "print(\"Train data shape:\")\n",
    "print(X_num_train.shape)\n",
    "print(\"Test data shape:\")\n",
    "print(X_num_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = -1\n",
    "n_test = -1\n",
    "X_train = X_num_train[:n_train]\n",
    "X_test = X_num_test[:n_test]\n",
    "y_train = y_array[:n_train]\n",
    "y_test = y_test_array[:n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - 10000 train - 10000 test -  mean=0.455717844843999 -std=0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.33539629333072046\n",
      "std: 0.0\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "n_try = 1\n",
    "loss_ = []\n",
    "for _ in range(n_try):\n",
    "    regressor.fit(X_train, np.log10(np.maximum(1,y_train)))\n",
    "\n",
    "    y_pred = 10 ** regressor.predict(X_test)\n",
    "    loss_.append(loss(y_test, y_pred))\n",
    "    \n",
    "print(\"mean:\",np.mean(loss_))\n",
    "print(\"std:\",np.std(loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.45728519563597547\n",
      "std: 0.015222342140296857\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "n_try = 10\n",
    "loss_ = []\n",
    "for _ in range(n_try):\n",
    "    regressor.fit(X_train, np.log1p(np.maximum(1,y_train)))\n",
    "\n",
    "    y_pred = np.exp(regressor.predict(X_test))\n",
    "    loss_.append(loss(y_test, y_pred))\n",
    "    \n",
    "print(\"mean:\",np.mean(loss_))\n",
    "print(\"std:\",np.std(loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_toy =y_train[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e+10, 1.e+10, 1.e+10, 1.e+10, 1.e+10, 1.e+10, 1.e+10, 1.e+10,\n",
       "       1.e+10, 1.e+10])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(y_toy,10000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31715693138700285\n"
     ]
    }
   ],
   "source": [
    "xg_boost = xgb.XGBRegressor( learning_rate=0.01,\n",
    "                         n_estimators=2000,\n",
    "                         #max_depth=4, min_child_weight=1,\n",
    "                         #gamma=0.6, subsample=0.7,\n",
    "                         #colsample_bytree=0.2, nthread=-1,\n",
    "                         #scale_pos_weight=1, seed=27,\n",
    "                         #reg_alpha=0.00006\n",
    "                       )\n",
    "xg_boost.fit(X_train, np.log10(np.maximum(y_train,1)))\n",
    "\n",
    "y_pred = 10 ** (xg_boost.predict(X_test))\n",
    "print(loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42888883590792337\n"
     ]
    }
   ],
   "source": [
    "xg_boost = xgb.XGBRegressor()\n",
    "regressor = AdaBoostRegressor(xg_boost)\n",
    "regressor.fit(X_train, np.log10(np.maximum(y_train,1)))\n",
    "\n",
    "y_pred = 10 ** (regressor.predict(X_test))\n",
    "print(loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "random_classifier = RandomForestRegressor()\n",
    "#cv = GroupShuffleSplit(n_splits=8, test_size=0.25)\n",
    "\n",
    "parameters = { 'max_features': np.arange(7,10),\n",
    "               'n_estimators': [8,9,10],\n",
    "               'min_samples_leaf': [10,20,30,\n",
    "                                    #100,200,500\n",
    "                                   ]}\n",
    "\n",
    "random_grid = GridSearchCV(random_classifier, parameters, scoring=fan_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 8, 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "-0.498 (+/-0.097) for {'max_features': 7, 'min_samples_leaf': 10, 'n_estimators': 8}\n",
      "-0.487 (+/-0.107) for {'max_features': 7, 'min_samples_leaf': 10, 'n_estimators': 9}\n",
      "-0.486 (+/-0.076) for {'max_features': 7, 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "-0.520 (+/-0.109) for {'max_features': 7, 'min_samples_leaf': 20, 'n_estimators': 8}\n",
      "-0.507 (+/-0.118) for {'max_features': 7, 'min_samples_leaf': 20, 'n_estimators': 9}\n",
      "-0.495 (+/-0.114) for {'max_features': 7, 'min_samples_leaf': 20, 'n_estimators': 10}\n",
      "-0.502 (+/-0.112) for {'max_features': 7, 'min_samples_leaf': 30, 'n_estimators': 8}\n",
      "-0.510 (+/-0.129) for {'max_features': 7, 'min_samples_leaf': 30, 'n_estimators': 9}\n",
      "-0.507 (+/-0.129) for {'max_features': 7, 'min_samples_leaf': 30, 'n_estimators': 10}\n",
      "-0.491 (+/-0.115) for {'max_features': 8, 'min_samples_leaf': 10, 'n_estimators': 8}\n",
      "-0.491 (+/-0.105) for {'max_features': 8, 'min_samples_leaf': 10, 'n_estimators': 9}\n",
      "-0.481 (+/-0.122) for {'max_features': 8, 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "-0.484 (+/-0.118) for {'max_features': 8, 'min_samples_leaf': 20, 'n_estimators': 8}\n",
      "-0.495 (+/-0.112) for {'max_features': 8, 'min_samples_leaf': 20, 'n_estimators': 9}\n",
      "-0.502 (+/-0.121) for {'max_features': 8, 'min_samples_leaf': 20, 'n_estimators': 10}\n",
      "-0.503 (+/-0.130) for {'max_features': 8, 'min_samples_leaf': 30, 'n_estimators': 8}\n",
      "-0.504 (+/-0.126) for {'max_features': 8, 'min_samples_leaf': 30, 'n_estimators': 9}\n",
      "-0.491 (+/-0.136) for {'max_features': 8, 'min_samples_leaf': 30, 'n_estimators': 10}\n",
      "-0.484 (+/-0.097) for {'max_features': 9, 'min_samples_leaf': 10, 'n_estimators': 8}\n",
      "-0.487 (+/-0.077) for {'max_features': 9, 'min_samples_leaf': 10, 'n_estimators': 9}\n",
      "-0.485 (+/-0.097) for {'max_features': 9, 'min_samples_leaf': 10, 'n_estimators': 10}\n",
      "-0.485 (+/-0.128) for {'max_features': 9, 'min_samples_leaf': 20, 'n_estimators': 8}\n",
      "-0.494 (+/-0.121) for {'max_features': 9, 'min_samples_leaf': 20, 'n_estimators': 9}\n",
      "-0.497 (+/-0.122) for {'max_features': 9, 'min_samples_leaf': 20, 'n_estimators': 10}\n",
      "-0.502 (+/-0.107) for {'max_features': 9, 'min_samples_leaf': 30, 'n_estimators': 8}\n",
      "-0.503 (+/-0.120) for {'max_features': 9, 'min_samples_leaf': 30, 'n_estimators': 9}\n",
      "-0.499 (+/-0.132) for {'max_features': 9, 'min_samples_leaf': 30, 'n_estimators': 10}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "0.5885108608686334\n"
     ]
    }
   ],
   "source": [
    "print(\"# Tuning hyper-parameters:\")\n",
    "print()\n",
    "\n",
    "random_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(random_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = random_grid.cv_results_['mean_test_score']\n",
    "stds = random_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, random_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, random_grid.predict(X_test)\n",
    "print(loss(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104334380.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 5.790908e-01 (+/- 1.131855e-02)\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=10,max_features = 8, min_samples_leaf = 10, max_depth = 10)\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', regressor)])\n",
    "\n",
    "cv = GroupShuffleSplit(n_splits=8, test_size=0.25)\n",
    "\n",
    "n_samples = 1000000\n",
    "#n_samples = len(X_df)\n",
    "scores_Xdf = -cross_val_score(clf, X_df[:n_samples], y_array[:n_samples], cv=cv, scoring=fan_loss, groups=X_df['Legal_ID'][:n_samples], n_jobs=2)\n",
    "\n",
    "print(\"mean: %e (+/- %e)\" % (scores_Xdf.mean(), scores_Xdf.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.710074e-01 (+/- 9.594759e-04)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.297797e-01 (+/- 1.967843e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.959337e-01 (+/- 3.453724e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.696194e-01 (+/- 7.739701e-04)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.880310e-01 (+/- 1.249568e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.463862e-01 (+/- 2.890824e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.078612e-01 (+/- 4.038989e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.876052e-01 (+/- 1.700589e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.994445e-01 (+/- 3.193338e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.195689e-01 (+/- 2.437443e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.110212e-01 (+/- 4.373147e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.994768e-01 (+/- 2.195771e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.705833e-01 (+/- 7.949954e-04)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.425038e-01 (+/- 2.397684e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.958295e-01 (+/- 4.710082e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.687522e-01 (+/- 5.285774e-04)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.910422e-01 (+/- 4.119130e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.338366e-01 (+/- 3.256209e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.069342e-01 (+/- 2.512481e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.888887e-01 (+/- 2.213214e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.982203e-01 (+/- 3.109357e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.268410e-01 (+/- 2.569857e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.152195e-01 (+/- 5.094566e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 4.011291e-01 (+/- 3.165293e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.702387e-01 (+/- 7.617711e-04)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.236026e-01 (+/- 3.167927e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.970964e-01 (+/- 2.725248e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.689567e-01 (+/- 7.582036e-04)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.886860e-01 (+/- 1.830242e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.164698e-01 (+/- 2.382141e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.064721e-01 (+/- 2.189770e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.900542e-01 (+/- 2.790483e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 4.006386e-01 (+/- 2.834191e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.358240e-01 (+/- 1.378929e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.144663e-01 (+/- 1.816531e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 4.007717e-01 (+/- 4.196044e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.702548e-01 (+/- 1.025001e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.452668e-01 (+/- 2.515812e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.949378e-01 (+/- 3.086028e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.689011e-01 (+/- 1.159716e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.889541e-01 (+/- 1.833639e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.365427e-01 (+/- 2.735211e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.085811e-01 (+/- 2.765759e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.919252e-01 (+/- 3.196436e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 4.004960e-01 (+/- 3.766522e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.352600e-01 (+/- 3.202916e-02)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.140947e-01 (+/- 4.775570e-03)\n",
      "===================\n",
      "max_features: 5 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 4.002406e-01 (+/- 1.940074e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.715042e-01 (+/- 9.272294e-04)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.292192e-01 (+/- 3.624872e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.932906e-01 (+/- 3.464753e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.705883e-01 (+/- 1.038516e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.841387e-01 (+/- 3.275047e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.372541e-01 (+/- 1.571942e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.017655e-01 (+/- 3.165915e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.840054e-01 (+/- 1.609936e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.932110e-01 (+/- 2.707008e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.176579e-01 (+/- 2.205559e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.084549e-01 (+/- 3.654222e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.941850e-01 (+/- 2.229306e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.710533e-01 (+/- 9.492454e-04)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.201114e-01 (+/- 8.668453e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.931659e-01 (+/- 2.429349e-03)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.699066e-01 (+/- 8.894680e-04)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.848318e-01 (+/- 1.165358e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.258759e-01 (+/- 1.523693e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.030645e-01 (+/- 3.195959e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.855913e-01 (+/- 3.173429e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.965816e-01 (+/- 4.128837e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.045039e-01 (+/- 2.090099e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.092159e-01 (+/- 2.091090e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.972064e-01 (+/- 2.983869e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.701544e-01 (+/- 7.013724e-04)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.249123e-01 (+/- 2.698235e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.980796e-01 (+/- 2.855102e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.696296e-01 (+/- 8.011783e-04)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.856336e-01 (+/- 1.709859e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.235279e-01 (+/- 2.996449e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.057628e-01 (+/- 2.748621e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.850073e-01 (+/- 1.705371e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.956823e-01 (+/- 2.493343e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.047971e-01 (+/- 2.188008e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.091041e-01 (+/- 3.564848e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.955755e-01 (+/- 3.062731e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.707453e-01 (+/- 1.339215e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.361013e-01 (+/- 3.020593e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.967931e-01 (+/- 1.812382e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.694992e-01 (+/- 9.271827e-04)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.847405e-01 (+/- 1.546621e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.043203e-01 (+/- 3.045085e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.036627e-01 (+/- 3.205986e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.853072e-01 (+/- 1.562555e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.970745e-01 (+/- 2.915544e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.162850e-01 (+/- 2.755521e-02)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.083850e-01 (+/- 2.674940e-03)\n",
      "===================\n",
      "max_features: 6 - n_estimators: 10 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.946036e-01 (+/- 1.339719e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.725141e-01 (+/- 6.291770e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.337498e-01 (+/- 3.063240e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.911408e-01 (+/- 5.249455e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.710614e-01 (+/- 7.397975e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.805713e-01 (+/- 7.546818e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.355069e-01 (+/- 2.613844e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.005313e-01 (+/- 4.266428e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.808505e-01 (+/- 1.457577e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.904960e-01 (+/- 2.604713e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.165336e-01 (+/- 2.866753e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.051856e-01 (+/- 2.968460e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 7 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.899642e-01 (+/- 2.261920e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.718047e-01 (+/- 7.444813e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.205646e-01 (+/- 3.155003e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.937415e-01 (+/- 3.430482e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.702649e-01 (+/- 6.441445e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.822629e-01 (+/- 1.138451e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.317400e-01 (+/- 2.713227e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.008897e-01 (+/- 2.598631e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.819704e-01 (+/- 1.008050e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.908766e-01 (+/- 1.242228e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.082654e-01 (+/- 1.979620e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.066163e-01 (+/- 1.965348e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 8 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.912531e-01 (+/- 1.975575e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.716542e-01 (+/- 1.333958e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.399198e-01 (+/- 2.490844e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.929576e-01 (+/- 3.564125e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.699158e-01 (+/- 7.800761e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: None\n",
      "mean: 3.819780e-01 (+/- 1.373438e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 10\n",
      "mean: 6.339119e-01 (+/- 2.292591e-02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 25\n",
      "mean: 4.012507e-01 (+/- 1.903068e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 10 - max_depth: 50\n",
      "mean: 3.825346e-01 (+/- 7.915259e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: None\n",
      "mean: 3.922634e-01 (+/- 4.496847e-04)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 10\n",
      "mean: 6.110660e-01 (+/- 3.153389e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 25\n",
      "mean: 4.068142e-01 (+/- 2.454316e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 9 - min_samples_leaf: 20 - max_depth: 50\n",
      "mean: 3.933162e-01 (+/- 3.954324e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: None\n",
      "mean: 3.710646e-01 (+/- 1.070048e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 10\n",
      "mean: 6.410534e-01 (+/- 3.106206e-02)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 25\n",
      "mean: 3.955351e-01 (+/- 4.213551e-03)\n",
      "===================\n",
      "max_features: 7 - n_estimators: 10 - min_samples_leaf: 1 - max_depth: 50\n",
      "mean: 3.697245e-01 (+/- 5.329907e-04)\n"
     ]
    }
   ],
   "source": [
    "for max_features_ in np.arange(5,11):\n",
    "    for n_estimators_ in np.arange(7,11):\n",
    "        for min_samples_leaf_ in [1,10,20]:\n",
    "            for max_depth_ in [None, 10,25,50]:\n",
    "                regressor = RandomForestRegressor(n_estimators=n_estimators_,\n",
    "                                                  max_features = max_features_, \n",
    "                                                  min_samples_leaf = min_samples_leaf_, \n",
    "                                                  max_depth = max_depth_)\n",
    "\n",
    "                clf = Pipeline(steps=[\n",
    "                    ('preprocessing', preprocessor),\n",
    "                    ('classifier', regressor)])\n",
    "\n",
    "                cv = GroupShuffleSplit(n_splits=8, test_size=0.25)\n",
    "\n",
    "                #n_samples = 1000\n",
    "                n_samples = len(X_df)\n",
    "                scores_Xdf = -cross_val_score(clf, X_df[:n_samples], y_array[:n_samples], cv=cv, scoring=fan_loss, groups=X_df['Legal_ID'][:n_samples], n_jobs=2)\n",
    "                print(\"===================\")\n",
    "                print(\"max_features: {} - n_estimators: {} - min_samples_leaf: {} - max_depth: {}\".format(max_features_, n_estimators_, min_samples_leaf_,max_depth_))\n",
    "                print(\"mean: %e (+/- %e)\" % (scores_Xdf.mean(), scores_Xdf.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*4*3*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Prediction of annual revenue using FAN\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions\\haiyen_submission_2 ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.12\u001b[0m  \u001b[38;5;150m69.221695\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.41\u001b[0m  \u001b[38;5;105m17.332377\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m   \u001b[38;5;218m9.392591\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.12\u001b[0m  \u001b[38;5;150m67.652653\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m18.304875\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m   \u001b[38;5;218m9.376451\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.12\u001b[0m  \u001b[38;5;150m67.769182\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m16.910084\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m   \u001b[38;5;218m9.808375\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m68.913406\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m17.027937\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m   \u001b[38;5;218m9.798610\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.12\u001b[0m  \u001b[38;5;150m69.383022\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m18.076140\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.43\u001b[0m  \u001b[38;5;218m10.011144\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m69.706588\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m17.974736\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m   \u001b[38;5;218m9.865078\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.12\u001b[0m  \u001b[38;5;150m69.745995\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m17.558545\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m  \u001b[38;5;218m10.209388\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.12\u001b[0m  \u001b[38;5;150m70.724842\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m  \u001b[38;5;105m16.877955\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.43\u001b[0m   \u001b[38;5;218m9.504135\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore     fan error         time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.12\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.003\u001b[0m  \u001b[38;5;150m69.1\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.96\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.42\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.001\u001b[0m  \u001b[38;5;105m17.5\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.52\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.42\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.003\u001b[0m   \u001b[38;5;218m9.7\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.28\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.42\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.42\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission --submission haiyen_submission_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Prediction of annual revenue using FAN\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions\\haiyen_submission_3 ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m70.247458\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.38\u001b[0m  \u001b[38;5;105m14.722892\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.500434\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m69.280671\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m14.574807\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.316836\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m70.303200\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m14.221292\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.509389\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m68.348161\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m14.417812\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.504932\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m70.654614\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m14.497395\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.543313\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m67.768689\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.38\u001b[0m  \u001b[38;5;105m14.048547\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.462246\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m70.041623\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m14.190686\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.642414\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m68.567552\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m14.063787\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m8.418402\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore     fan error         time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.13\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.002\u001b[0m   \u001b[38;5;150m69.4\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m1.0\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.39\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.002\u001b[0m  \u001b[38;5;105m14.3\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.23\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.37\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.001\u001b[0m   \u001b[38;5;218m8.5\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.09\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission --submission haiyen_submission_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Prediction of annual revenue using FAN\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions\\haiyen_submission_4 ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m83.321746\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.919608\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m   \u001b[38;5;218m9.693214\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m83.941555\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.952746\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m  \u001b[38;5;218m10.020159\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m81.673289\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m18.008927\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m9.976913\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m82.052088\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m18.047013\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m  \u001b[38;5;218m10.035290\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.17\u001b[0m  \u001b[38;5;150m83.762078\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.41\u001b[0m  \u001b[38;5;105m17.794741\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m  \u001b[38;5;218m10.539607\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m84.107375\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m18.000975\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m  \u001b[38;5;218m10.041177\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m84.618323\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.969418\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m9.830553\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m86.550074\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.906311\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m  \u001b[38;5;218m10.155771\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore     fan error         time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m   \u001b[38;5;10m\u001b[1m0.15\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.01\u001b[0m  \u001b[38;5;150m83.8\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m1.42\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.39\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.006\u001b[0m  \u001b[38;5;105m17.9\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.07\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.38\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.008\u001b[0m  \u001b[38;5;218m10.0\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.23\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission --submission haiyen_submission_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Prediction of annual revenue using FAN\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions\\haiyen_submission_5 ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m66.696815\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m16.981612\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.40\u001b[0m   \u001b[38;5;218m9.595214\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m67.931496\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m16.754518\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m   \u001b[38;5;218m9.413165\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m66.213099\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m16.980257\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m   \u001b[38;5;218m9.597155\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m66.554931\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.41\u001b[0m  \u001b[38;5;105m16.979525\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m   \u001b[38;5;218m9.354184\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m66.529934\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m17.201379\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m   \u001b[38;5;218m9.298321\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m66.252864\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m17.587882\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m   \u001b[38;5;218m9.315075\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m67.140856\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m17.326568\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.40\u001b[0m   \u001b[38;5;218m9.390939\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m66.167774\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m17.137401\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.40\u001b[0m   \u001b[38;5;218m9.329856\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore     fan error         time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.15\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.004\u001b[0m  \u001b[38;5;150m66.7\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.56\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m   \u001b[38;5;12m\u001b[1m0.4\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.002\u001b[0m  \u001b[38;5;105m17.1\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.24\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.39\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.003\u001b[0m   \u001b[38;5;218m9.4\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.11\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission --submission haiyen_submission_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Prediction of annual revenue using FAN\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions\\haiyen_submission_6 ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m69.970058\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.38\u001b[0m  \u001b[38;5;105m17.007150\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.39\u001b[0m   \u001b[38;5;218m9.430250\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m69.726557\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.035280\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m9.231528\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m67.877645\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m16.855330\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m9.522130\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 3\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.15\u001b[0m  \u001b[38;5;150m68.644936\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.40\u001b[0m  \u001b[38;5;105m17.028595\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.37\u001b[0m   \u001b[38;5;218m9.612817\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 4\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m69.101283\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m16.933542\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m   \u001b[38;5;218m9.268121\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 5\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m67.550004\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m16.967211\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m   \u001b[38;5;218m9.213238\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 6\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.13\u001b[0m  \u001b[38;5;150m69.305604\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.241723\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m   \u001b[38;5;218m9.319736\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 7\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error       time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m       \u001b[38;5;10m\u001b[1m0.14\u001b[0m  \u001b[38;5;150m71.547929\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m  \u001b[38;5;105m17.043847\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m   \u001b[38;5;218m9.359147\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore     fan error         time\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.14\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m0.007\u001b[0m  \u001b[38;5;150m69.2\u001b[0m\u001b[38;5;150m\u001b[38;5;150m\u001b[0m\u001b[0m\u001b[38;5;150m1.18\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.39\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.004\u001b[0m   \u001b[38;5;105m17.0\u001b[0m\u001b[38;5;105m\u001b[38;5;105m\u001b[0m\u001b[0m\u001b[38;5;105m0.1\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m0.38\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.005\u001b[0m   \u001b[38;5;218m9.4\u001b[0m\u001b[38;5;218m\u001b[38;5;218m\u001b[0m\u001b[0m\u001b[38;5;218m0.13\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore  fan error\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m       \u001b[38;5;12m\u001b[1m0.39\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m        \u001b[38;5;1m\u001b[1m0.38\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission --submission haiyen_submission_6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
